# Model configuration
model:
  in_channels: 2
  base_channels: 128
  latent_dim: 64
  c_mults: [[1, 1], [1, 2], [2, 4], [4, 8], [8, 16]]
  strides: [2, 4, 4, 8, 8]

# Training configuration
training:
  batch_size: 4
  num_epochs: 500
  learning_rate: 2.0e-4
  weight_decay: 1.0e-4

  # Loss weights
  kl_weight: 1.0e-6 # Start small, will anneal
  kl_anneal_epochs: 2 # Gradually increase KL weight over these epochs

  # Optimizer
  adam_betas: [0.9, 0.999]
  gradient_clip: 1.0

# Data configuration
data:
  train_dir: "./data/vocal_dataset"
  target_length: 40960
  target_sr: 44100
  train_split: 0.9 # 90% train, 10% validation
  num_workers: 2

# Checkpoint configuration
checkpointing:
  save_dir: "./checkpoints"
  save_every_n_epochs: 2
  keep_last_n: 3 # Keep only last 3 checkpoints to save space

# Logging configuration
logging:
  wandb_project: "LyraCodec"
  log_every_n_steps: 10
  save_audio_every_n_epochs: 10 # Save audio samples to WandB
  num_audio_samples: 4 # Number of audio samples to log

# System
system:
  device: "cuda" # or "cpu"
  mixed_precision: true # Use automatic mixed precision
