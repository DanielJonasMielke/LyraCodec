hyperparameters:
  training:
    learning_rate: 0.0001 # 1e-4
    lr_scheduler:
      warmup_steps: 700
      inv_gamma: 200000
      power: 0.5
    batch_size: 10
    num_epochs: 1000
    weight_decay: 0.0001
    kl_weight: 0.0001 # 1e-4
    kl_warmup_steps: 2600
    betas: [0.8, 0.99]
    validate_and_save_every: 1 # in epochs
    log_interval: 4 # in training steps
    generate_sample_interval: 200 # in training steps
    checkpoint_interval: 300 # in training steps
    stft_loss_params:
      fft_sizes: [2048, 1024, 512, 256, 128, 64, 32]
      hop_sizes: [512, 256, 128, 64, 32, 16, 8]
      win_lengths: [2048, 1024, 512, 256, 128, 64, 32]
      perceptual_weighting: true
  data:
    path: data/vocal_dataset/
    sample_rate: 44100
    target_length: 71680 # ~1.625 seconds
    num_workers: 4
  model:
    in_channels: 2
    base_channels: 128
    latent_dim: 64
    c_mults: [[1, 1], [1, 2], [2, 4], [4, 8], [8, 16]]
    strides: [2, 4, 4, 8, 8]
device:
  use_cuda: true
wandb:
  project: VocalVAE
  run_name: null
